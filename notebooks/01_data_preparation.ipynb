{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e0b32db",
   "metadata": {},
   "source": [
    "# ZEvent 2025 - Data Preparation\n",
    "\n",
    "Ce notebook combine l'extraction et le nettoyage des donn√©es ZEvent 2025.\n",
    "\n",
    "## Sources de donn√©es\n",
    "- **API ZEvent** : Statistiques officielles, goals, √©v√©nements\n",
    "- **SullyGnome** : M√©triques Twitch compl√©mentaires\n",
    "\n",
    "## Outputs\n",
    "- Donn√©es consolid√©es dans `data/clean/`\n",
    "- Datasets pr√™ts pour analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b8ad5f",
   "metadata": {},
   "source": [
    "## 1. Setup et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e41e6669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Projet : c:\\Users\\Linw√´\\Documents\\ZEvent2025_data_analyse\n",
      "üìä Donn√©es raw : c:\\Users\\Linw√´\\Documents\\ZEvent2025_data_analyse\\data\\raw\n",
      "‚ú® Donn√©es clean : c:\\Users\\Linw√´\\Documents\\ZEvent2025_data_analyse\\data\\clean\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des chemins\n",
    "project_root = Path.cwd().parent  # Remonter depuis notebooks/\n",
    "data_dir = project_root / 'data'\n",
    "raw_dir = data_dir / 'raw'\n",
    "clean_dir = data_dir / 'clean'\n",
    "\n",
    "print(f\"üìÅ Projet : {project_root}\")\n",
    "print(f\"üìä Donn√©es raw : {raw_dir}\")\n",
    "print(f\"‚ú® Donn√©es clean : {clean_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1640417",
   "metadata": {},
   "source": [
    "## 2. Extraction API ZEvent\n",
    "\n",
    "R√©cup√©ration des donn√©es depuis l'API officielle ZEvent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3093019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ statistics: Donn√©es charg√©es depuis all_statistics.json (5 √©l√©ments)\n",
      "üìÅ donation_goals: Donn√©es charg√©es depuis donation_goals.json (5442 √©l√©ments)\n",
      "üìÅ event_schedule: Donn√©es charg√©es depuis event_schedule.json (57 √©l√©ments)\n"
     ]
    }
   ],
   "source": [
    "# API ZEvent - URLs et mapping des fichiers\n",
    "BASE_URL = \"https://zevent-api.gdoc.fr\"\n",
    "endpoints = {\n",
    "    'statistics': f\"{BASE_URL}/statistics\",\n",
    "    'donation_goals': f\"{BASE_URL}/donation_goals\", \n",
    "    'event_schedule': f\"{BASE_URL}/event_schedule\"\n",
    "}\n",
    "\n",
    "# Mapping pour les noms de fichiers alternatifs\n",
    "file_mapping = {\n",
    "    'statistics': ['statistics.json', 'all_statistics.json', 'individual_streamer_stats.json'],\n",
    "    'donation_goals': ['donation_goals.json'],\n",
    "    'event_schedule': ['event_schedule.json']\n",
    "}\n",
    "\n",
    "def fetch_zevent_data(endpoint_name, url):\n",
    "    \"\"\"R√©cup√®re les donn√©es d'un endpoint ZEvent ou charge depuis cache\"\"\"\n",
    "    # V√©rifier les fichiers possibles pour cet endpoint\n",
    "    possible_files = file_mapping.get(endpoint_name, [f\"{endpoint_name}.json\"])\n",
    "    \n",
    "    for filename in possible_files:\n",
    "        raw_file = raw_dir / 'zevent_api' / filename\n",
    "        if raw_file.exists():\n",
    "            try:\n",
    "                with open(raw_file, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                print(f\"üìÅ {endpoint_name}: Donn√©es charg√©es depuis {filename} ({len(data)} √©l√©ments)\")\n",
    "                return data\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Erreur lecture {filename}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Sinon, essayer de r√©cup√©rer depuis l'API\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Sauvegarde raw\n",
    "        raw_file = raw_dir / 'zevent_api' / f\"{endpoint_name}.json\"\n",
    "        raw_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        with open(raw_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(response.json(), f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"‚úÖ {endpoint_name}: {len(response.json())} √©l√©ments (nouveau)\")\n",
    "        return response.json()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå API {endpoint_name} indisponible: {e}\")\n",
    "        print(f\"   ‚Üí Aucune donn√©e trouv√©e pour {endpoint_name}\")\n",
    "        return None\n",
    "\n",
    "# Extraction des donn√©es\n",
    "zevent_data = {}\n",
    "for name, url in endpoints.items():\n",
    "    zevent_data[name] = fetch_zevent_data(name, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c484c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ V√©rification dossier API : c:\\Users\\Linw√´\\Documents\\ZEvent2025_data_analyse\\data\\raw\\zevent_api\n",
      "üìÑ Fichiers JSON trouv√©s: 4\n",
      "   ‚úÖ all_statistics.json: 5 √©l√©ments\n",
      "   ‚úÖ donation_goals.json: 5442 √©l√©ments\n",
      "   ‚úÖ event_schedule.json: 57 √©l√©ments\n",
      "   ‚úÖ individual_streamer_stats.json: 319 √©l√©ments\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic des donn√©es existantes\n",
    "zevent_api_dir = raw_dir / 'zevent_api'\n",
    "print(f\"üìÅ V√©rification dossier API : {zevent_api_dir}\")\n",
    "\n",
    "if zevent_api_dir.exists():\n",
    "    existing_files = list(zevent_api_dir.glob('*.json'))\n",
    "    print(f\"üìÑ Fichiers JSON trouv√©s: {len(existing_files)}\")\n",
    "    for file in existing_files:\n",
    "        try:\n",
    "            with open(file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            print(f\"   ‚úÖ {file.name}: {len(data)} √©l√©ments\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå {file.name}: Erreur lecture - {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Dossier zevent_api inexistant\")\n",
    "    zevent_api_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(\"‚úÖ Dossier cr√©√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f4eb43",
   "metadata": {},
   "source": [
    "## 3. Traitement SullyGnome\n",
    "\n",
    "Consolidation des fichiers CSV SullyGnome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c472e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Fichiers SullyGnome trouv√©s: 5\n",
      "   ZEVENT - most watched Twitch channels - SullyGnome - page 1.csv: 100 streamers\n",
      "   ZEVENT - most watched Twitch channels - SullyGnome - page 2.csv: 100 streamers\n",
      "   ZEVENT - most watched Twitch channels - SullyGnome - page 3.csv: 100 streamers\n",
      "   ZEVENT - most watched Twitch channels - SullyGnome - page 4.csv: 100 streamers\n",
      "   ZEVENT - most watched Twitch channels - SullyGnome - page 5.csv: 63 streamers\n",
      "\n",
      "üìä Total SullyGnome: 463 streamers\n",
      "‚ú® Apr√®s d√©doublonnage: 463 streamers uniques\n"
     ]
    }
   ],
   "source": [
    "# Chargement et consolidation SullyGnome\n",
    "sullygnome_dir = raw_dir / 'sullygnome'\n",
    "csv_files = list(sullygnome_dir.glob('*.csv'))\n",
    "\n",
    "print(f\"üìÅ Fichiers SullyGnome trouv√©s: {len(csv_files)}\")\n",
    "\n",
    "# Consolidation\n",
    "all_pages = []\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    all_pages.append(df)\n",
    "    print(f\"   {csv_file.name}: {len(df)} streamers\")\n",
    "\n",
    "if all_pages:\n",
    "    df_sullygnome = pd.concat(all_pages, ignore_index=True)\n",
    "    print(f\"\\nüìä Total SullyGnome: {len(df_sullygnome)} streamers\")\n",
    "    \n",
    "    # Nettoyage basique\n",
    "    df_sullygnome = df_sullygnome.drop_duplicates(subset=['Channel'])\n",
    "    df_sullygnome['Channel'] = df_sullygnome['Channel'].str.lower().str.strip()\n",
    "    \n",
    "    print(f\"‚ú® Apr√®s d√©doublonnage: {len(df_sullygnome)} streamers uniques\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Aucun fichier SullyGnome trouv√©\")\n",
    "    df_sullygnome = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3357bdb9",
   "metadata": {},
   "source": [
    "## 4. Nettoyage et Enrichissement\n",
    "\n",
    "Pr√©paration des datasets finaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e9f4cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Type de donn√©es: <class 'dict'>\n",
      "üìä Cl√©s disponibles: ['0uahleouff', '2old4stream', 'adyboo', 'airkagaming', 'alexclick', 'allmight__one', 'alphacast', 'anaee', 'anaonair', 'angledroit', 'antistar', 'antoinedaniel', 'arnaquemoisitupeux', 'artemize', 'as2pik', 'avamind', 'azghaaar', 'bagherajones', 'barbe___douce', 'bartgeo', 'bastiui', 'bclv4', 'behop_veek', 'benzaie', 'bigbadhater_fr', 'bluestardust_', 'boitameu', 'boomnasty_', 'bouddhiste', 'brickmitri', 'broocoline', 'brunouniverssimu', 'brybry', 'byilhann', 'cailloute', 'captainfracas', 'chaab', 'chaton_sauvage_', 'chester_ttv', 'chezbubulle', 'chowh1', 'christellelebaillyauteur', 'citronviolet', 'clara_l_exploratrice', 'clem_mlrt', 'clemovitch', 'clubpingouin_trash', 'coffee', 'crocodyletv', 'crosswax', 'cruelladk', 'damdamlive', 'dams_ow', 'david_kyden', 'deavild', 'deejaymakina', 'did0us', 'doigby', 'domingo', 'doxtv75', 'drakeoz_', 'drfeelgood', 'drfrenesy', 'echyr_', 'elbe_poly', 'elfyaa', 'elizyatv', 'elnoraeleo', 'elyhonair', 'elypwet', 'e_mule', 'enjoyphoenix', 'estebancano_7', 'etoile_ow', 'etoiles', 'euphoriasis', 'evan91380_', 'evoxia', 'expat_malgre_lui', 'eymryc', 'eziogdsp', 'fabdcolson', 'falkalive', 'farodgames', 'fausthea', 'f_bardino', 'fefegg', 'flamby', 'flavienalexzander', 'flaviestch', 'flonflon', 'flynnwinch', 'franck_miller', 'frozencrystal', 'fukano', 'gamesdreamy', 'general_mass', 'gf_iguel', 'gius', 'golriver_', 'gom4rt', 'greg16s', 'guimauseterrier', 'hammerkick', 'harumate', 'hctuan', 'heillinel', 'helydia', 'hortyunderscore', 'hosarny', 'hugoauperchoir', 'huzounet', 'hytanie', 'ikerttvv', 'imsofresh', 'jackplaypz', 'jardistream', 'jarlspunk', 'jawedcs', 'jeanbaptisteshow', 'jengo_m', 'jennyyl', 'jessbond', 'jidun', 'jilanocast', 'jirayalecochon', 'jltomy', 'joelafritt_', 'joueur_du_grenier', 'joyca', 'julgane', 'just1chat', 'kahleeya', 'kammy64', 'kaosvmd', 'kapslockart', 'karoviper', 'katchanvt', 'keeps', 'kejinn', 'kemist_c10h15n', 'kenbogard', 'kennystream', 'kensei_fr', 'kikitchiwi', 'klr_stream', 'koala_cosy', 'koripeluche', 'kunder_on', 'kusa', 'kwikwiii', 'kyunesswhale', 'la_capitainerie', 'lakalzone', 'lalain', 'laniyelle', 'lapi', 'latavernedepatatus', 'leocrow_', 'lepapyofficiel', 'lepirateroux', 'leprotagonistetv', 'les_archives', 'lesgoules', 'linca', 'littlebigwhale', 'lofimaria_', 'lunae', 'lunium', 'lynkus_', 'lypning', 'm4fgaming', 'm4ll4ury', 'magarky', 'mahyars', 'maitrearmand', 'maitreleee', 'malganyr', 'manaryuujin', 'marcelpignol', 'marco', 'maricanne', 'maryhealthtv', 'mastu', 'mathox', 'mavienormale', 'medalinya', 'memez94', 'menou', 'merci_raph', 'meteorann', 'mialymusic', 'michaelbielli', 'mielcrapouille', 'miisterkel', 'misscliick_', 'mistermv', 'misterpacothai', 'mistyee', 'moman', 'momos_vision', 'monkyjv', 'monsieurfoxx', 'morrigh4n', 'mrderiv', 'mrquarate', 'mushu', 'music_oceane', 'mynthos', 'n0tizi', 'nakastream', 'nanie_nao', 'natsuko', 'necotho', 'nejda', 'nerdfactory', 'neru', 'nia_c', 'nico_la', 'nihiiltv', 'nikotb_', 'nogodi', 'noki_pubg', 'nunakeau', 'nyamassis', 'nykho', 'oliarius', 'olithinoa', 'otsunatv', 'ouilli', 'papy_grant', 'petitbiscuit_', 'petitours', 'peurle_ow', 'pixeloctet', 'play_mk8', 'poachimpa', 'ponce', 'pressea', 'priscillaliaud', 'proteam', 'purpleofficiel', 'pwnz_', 'r3ymann', 'ravencross', 'rbcop_', 'recalbox', 'recharg_ing', 'redairazor', 'ribodanslasauce', 'rivenzi', 'roi_louis', 'ryuuna_vt', 'sakor_', 'samueletienne', 'saniahasna', 'sapeuh', 'saruei', 'sawpalin', 'schkaia', 'scok', 'seroths', 'sgauth', 'shakaam', 'shisheyu', 'shubbley', 'shynouh', 'skerax', 'skyzio_', 'slyders_hs', 'soharumi', 'solaryhs', 'sol_hms', 'solkarine', 'splinter', 'sratuke', 'ss7even', 'st0netv', 'stanrenart', 'stelliosow', 'strey_lol', 'sturry316', 'sundae', 'swifiiii', 'sylvainlyve', 'symphoniya_', 'taelth', 'tamaroush_', 'tchouuki', 'tehleadersheep', 'teuff_', 'thefoxeur', 'thegreatreview', 'theguill84', 'theholomovement', 'theodort', 'tipstevens', 'togalock_fr', 'toulouselaststock', 'trinity', 'tsunadida', 'ultia', 'varg31', 'verveine_', 'voxioo', 'vulvyqueen', 'warhadventure', 'welliah', 'windsurfer2105', 'wingo', 'yannock_', 'yodahkiin_', 'ysadhora', 'zacknani', 'zayphira', 'zerator', 'zevent', 'zeventplays', 'zimas']\n",
      "üìä Streamers ZEvent: 319 streamers\n",
      "üìã Colonnes: ['donation', 'pools', 'times', 'viewers', 'viewers_max']\n",
      "üíæ Sauvegarde: streamers_data.csv\n",
      "üíæ Sauvegarde: sullygnome_consolidated.csv\n"
     ]
    }
   ],
   "source": [
    "# Traitement des donn√©es streamers ZEvent\n",
    "streamers_dir = clean_dir / 'streamers'\n",
    "streamers_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Chargement et analyse du fichier individual_streamer_stats\n",
    "try:\n",
    "    with open(raw_dir / 'zevent_api' / 'individual_streamer_stats.json', 'r', encoding='utf-8') as f:\n",
    "        streamer_stats = json.load(f)\n",
    "    \n",
    "    print(f\"üìä Type de donn√©es: {type(streamer_stats)}\")\n",
    "    if isinstance(streamer_stats, dict):\n",
    "        print(f\"üìä Cl√©s disponibles: {list(streamer_stats.keys())}\")\n",
    "        # Si c'est un dict, prendre les valeurs ou une cl√© sp√©cifique\n",
    "        if 'streamers' in streamer_stats:\n",
    "            streamer_list = streamer_stats['streamers']\n",
    "        elif isinstance(list(streamer_stats.values())[0], list):\n",
    "            streamer_list = list(streamer_stats.values())[0]\n",
    "        else:\n",
    "            streamer_list = list(streamer_stats.values())\n",
    "    elif isinstance(streamer_stats, list):\n",
    "        streamer_list = streamer_stats\n",
    "    else:\n",
    "        streamer_list = []\n",
    "    \n",
    "    if streamer_list and len(streamer_list) > 0:\n",
    "        df_zevent = pd.DataFrame(streamer_list)\n",
    "        print(f\"üìä Streamers ZEvent: {len(df_zevent)} streamers\")\n",
    "        print(f\"üìã Colonnes: {list(df_zevent.columns)}\")\n",
    "        \n",
    "        # Nettoyage username pour matching\n",
    "        username_col = None\n",
    "        for col in ['username', 'name', 'channel', 'streamer']:\n",
    "            if col in df_zevent.columns:\n",
    "                username_col = col\n",
    "                break\n",
    "        \n",
    "        if username_col:\n",
    "            df_zevent['username_clean'] = df_zevent[username_col].str.lower().str.strip()\n",
    "            print(f\"‚úÖ Colonne username_clean cr√©√©e depuis {username_col}\")\n",
    "        \n",
    "        # Sauvegarde streamers base\n",
    "        df_zevent.to_csv(streamers_dir / 'streamers_data.csv', index=False)\n",
    "        print(f\"üíæ Sauvegarde: streamers_data.csv\")\n",
    "        \n",
    "        # Enrichissement avec SullyGnome si disponible\n",
    "        if not df_sullygnome.empty and 'username_clean' in df_zevent.columns:\n",
    "            # Matching par username\n",
    "            df_enriched = df_zevent.merge(\n",
    "                df_sullygnome.rename(columns={'Channel': 'username_clean'}),\n",
    "                on='username_clean',\n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            # Sauvegarde enrichie\n",
    "            df_enriched.to_csv(streamers_dir / 'zevent_sullygnome_enriched.csv', index=False)\n",
    "            print(f\"üíæ Sauvegarde: zevent_sullygnome_enriched.csv\")\n",
    "            \n",
    "            # Stats de matching\n",
    "            sullygnome_cols = [col for col in df_enriched.columns if col in df_sullygnome.columns]\n",
    "            if sullygnome_cols:\n",
    "                matched = df_enriched.dropna(subset=[sullygnome_cols[0]]).shape[0]\n",
    "                print(f\"üîó Matching r√©ussi: {matched}/{len(df_zevent)} streamers\")\n",
    "        \n",
    "        # Sauvegarde SullyGnome consolid√©\n",
    "        if not df_sullygnome.empty:\n",
    "            df_sullygnome.to_csv(streamers_dir / 'sullygnome_consolidated.csv', index=False)\n",
    "            print(f\"üíæ Sauvegarde: sullygnome_consolidated.csv\")\n",
    "            \n",
    "    else:\n",
    "        print(\"‚ùå Aucune donn√©e streamer trouv√©e\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur traitement streamers: {e}\")\n",
    "    # Utiliser les donn√©es existantes si le fichier CSV existe d√©j√†\n",
    "    existing_streamers = streamers_dir / 'streamers_data.csv'\n",
    "    if existing_streamers.exists():\n",
    "        print(\"   ‚Üí Utilisation des donn√©es existantes\")\n",
    "    else:\n",
    "        print(\"   ‚Üí Aucune donn√©e disponible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c45b16",
   "metadata": {},
   "source": [
    "## 5. Sauvegarde Donn√©es √âv√©nements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d947c626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Goals sauvegard√©s: 5442 objectifs\n",
      "üíæ Planning sauvegard√©: 57 √©v√©nements\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde goals et √©v√©nements\n",
    "events_dir = clean_dir / 'events'\n",
    "events_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Donation goals\n",
    "if zevent_data.get('donation_goals'):\n",
    "    df_goals = pd.DataFrame(zevent_data['donation_goals'])\n",
    "    df_goals.to_csv(events_dir / 'donation_goals.csv', index=False)\n",
    "    print(f\"üíæ Goals sauvegard√©s: {len(df_goals)} objectifs\")\n",
    "\n",
    "# Event schedule  \n",
    "if zevent_data.get('event_schedule'):\n",
    "    df_schedule = pd.DataFrame(zevent_data['event_schedule'])\n",
    "    df_schedule.to_csv(events_dir / 'event_schedule.csv', index=False)\n",
    "    print(f\"üíæ Planning sauvegard√©: {len(df_schedule)} √©v√©nements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ec7547",
   "metadata": {},
   "source": [
    "## 6. R√©sum√© des Donn√©es Pr√©par√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d312f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üìä R√âSUM√â DES DONN√âES PR√âPAR√âES\n",
      "==================================================\n",
      "‚úÖ events\\donation_goals.csv: 5442 lignes, 10 colonnes\n",
      "‚úÖ events\\event_schedule.csv: 57 lignes, 7 colonnes\n",
      "‚úÖ streamers\\streamers_data.csv: 319 lignes, 5 colonnes\n",
      "‚úÖ streamers\\streamers_detailed_stats.csv: 326 lignes, 15 colonnes\n",
      "‚úÖ streamers\\sullygnome_consolidated.csv: 463 lignes, 12 colonnes\n",
      "‚úÖ streamers\\sullygnome_raw_consolidated.csv: 463 lignes, 15 colonnes\n",
      "‚úÖ streamers\\sullygnome_zevent_consolidated.csv: 463 lignes, 19 colonnes\n",
      "‚úÖ streamers\\zevent_sullygnome_enriched.csv: 316 lignes, 26 colonnes\n",
      "‚úÖ temporal\\donations_evolution.csv: 110 lignes, 3 colonnes\n",
      "‚úÖ temporal\\viewers_evolution.csv: 111 lignes, 3 colonnes\n",
      "\n",
      "üìÅ Tous les fichiers dans: c:\\Users\\Linw√´\\Documents\\ZEvent2025_data_analyse\\data\\clean\n",
      "‚ú® Donn√©es pr√™tes pour l'analyse !\n"
     ]
    }
   ],
   "source": [
    "# R√©sum√© final\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìä R√âSUM√â DES DONN√âES PR√âPAR√âES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# V√©rification des fichiers cr√©√©s\n",
    "clean_files = list(clean_dir.rglob('*.csv'))\n",
    "for file in clean_files:\n",
    "    df_check = pd.read_csv(file)\n",
    "    relative_path = file.relative_to(clean_dir)\n",
    "    print(f\"‚úÖ {relative_path}: {len(df_check)} lignes, {len(df_check.columns)} colonnes\")\n",
    "\n",
    "print(f\"\\nüìÅ Tous les fichiers dans: {clean_dir}\")\n",
    "print(\"‚ú® Donn√©es pr√™tes pour l'analyse !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
